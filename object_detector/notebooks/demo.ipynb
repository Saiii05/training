{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo\n",
    "\n",
    "This notebook demonstrates how to use a trained object detection model to perform inference on new images. It covers:\n",
    "1. Loading the trained model checkpoint.\n",
    "2. Preprocessing an input image.\n",
    "3. Performing inference to get predictions (class logits, box coordinates).\n",
    "4. Post-processing predictions (Softmax, NMS, decoding boxes).\n",
    "5. Drawing the detected bounding boxes on the original image and displaying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the project root to sys.path to allow importing from src\n",
    "# Assuming the notebook is in object_detector/notebooks/\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from src.model import ObjectDetectionModel\n",
    "from src.transforms import get_transform\n",
    "from src.dataset import PASCAL_VOC_CLASSES # Tuple of foreground class names\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_PATH = \"../models_checkpoints/checkpoint_best.pth\" \n",
    "# User should ensure this path is correct relative to the notebook's location.\n",
    "# Example: if notebook is in 'object_detector/notebooks' and checkpoints are in 'object_detector/models_checkpoints'\n",
    "\n",
    "IMAGE_DIR = \"../test_images/\" \n",
    "# User should create this directory in the project root (e.g., object_detector/test_images/)\n",
    "# and place their test images there.\n",
    "\n",
    "DEFAULT_TEST_IMAGE = \"example.jpg\" # A default image name to look for in IMAGE_DIR\n",
    "\n",
    "IMAGE_SIZE = 300 # Must match the image size the model was trained on\n",
    "SCORE_THRESHOLD_DISPLAY = 0.5 # Confidence threshold for displaying detected boxes\n",
    "IOU_THRESHOLD_NMS = 0.45      # IoU threshold for Non-Maximum Suppression\n",
    "NUM_CLASSES_FG = 20           # Number of foreground classes (e.g., 20 for Pascal VOC)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"PASCAL VOC Classes (foreground): {PASCAL_VOC_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = ObjectDetectionModel(\n",
    "    num_classes_fg=NUM_CLASSES_FG, \n",
    "    image_size_for_default_boxes=(IMAGE_SIZE, IMAGE_SIZE)\n",
    ")\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "        \n",
    "        # Handle potential 'module.' prefix if model was saved using DataParallel\n",
    "        model_state_dict = checkpoint['model_state_dict']\n",
    "        if all(key.startswith('module.') for key in model_state_dict.keys()):\n",
    "            print(\"Removing 'module.' prefix from checkpoint keys.\")\n",
    "            corrected_state_dict = {k.replace('module.', ''): v for k, v in model_state_dict.items()}\n",
    "        else:\n",
    "            corrected_state_dict = model_state_dict\n",
    "            \n",
    "        model.load_state_dict(corrected_state_dict)\n",
    "        model.to(DEVICE)\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        print(f\"Model loaded successfully from {CHECKPOINT_PATH}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}\")\n",
    "        print(\"Please ensure the checkpoint is valid and compatible with the model.\")\n",
    "        model = None # Ensure model is None if loading failed\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {CHECKPOINT_PATH}.\")\n",
    "    print(\"Please place your trained model checkpoint at the specified path or update CHECKPOINT_PATH.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def prepare_image(image_path, image_size, device):\n",
    "    \"\"\"\n",
    "    Loads a PIL image, applies transformations, and prepares it for the model.\n",
    "    Returns the image tensor and the original PIL image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pil_image = Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image not found at {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    transform = get_transform(train=False, resize_size=(image_size, image_size))\n",
    "    img_tensor = transform(pil_image)\n",
    "    return img_tensor.unsqueeze(0).to(device), pil_image\n",
    "\n",
    "def draw_boxes_on_image(pil_img, boxes_xyxy_norm, labels, scores, class_names, score_thresh):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes, labels, and scores on a PIL image.\n",
    "    boxes_xyxy_norm: Normalized [xmin, ymin, xmax, ymax] coordinates [0,1].\n",
    "    labels: Integer class indices (foreground, 0 to N-1).\n",
    "    scores: Confidence scores for each box.\n",
    "    class_names: Tuple/list of foreground class names.\n",
    "    score_thresh: Threshold to display boxes.\n",
    "    \"\"\"\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    \n",
    "    # Define a list of distinct colors for classes\n",
    "    # Using a fixed list of colors. For more classes, this list would need to be extended.\n",
    "    colors = [\n",
    "        \"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"orange\", \"cyan\", \"magenta\",\n",
    "        \"brown\", \"pink\", \"gray\", \"olive\", \"navy\", \"teal\", \"maroon\", \"lime\",\n",
    "        \"aqua\", \"fuchsia\", \"silver\", \"gold\"\n",
    "    ] * (len(class_names) // 20 + 1) # Repeat colors if more than 20 classes\n",
    "\n",
    "    try:\n",
    "        # Try to load a default font, fallback if not available\n",
    "        font = ImageFont.load_default()\n",
    "    except IOError:\n",
    "        print(\"Default font not found. Using a basic font representation.\")\n",
    "        font = None\n",
    "\n",
    "    for i in range(boxes_xyxy_norm.shape[0]):\n",
    "        if scores[i] < score_thresh:\n",
    "            continue\n",
    "\n",
    "        # Denormalize box coordinates\n",
    "        xmin = boxes_xyxy_norm[i, 0] * pil_img.width\n",
    "        ymin = boxes_xyxy_norm[i, 1] * pil_img.height\n",
    "        xmax = boxes_xyxy_norm[i, 2] * pil_img.width\n",
    "        ymax = boxes_xyxy_norm[i, 3] * pil_img.height\n",
    "\n",
    "        box_coords = [(xmin, ymin), (xmax, ymax)]\n",
    "        label_idx = labels[i].item()\n",
    "        class_name = class_names[label_idx] if label_idx < len(class_names) else f\"Class_{label_idx}\"\n",
    "        \n",
    "        label_text = f\"{class_name}: {scores[i]:.2f}\"\n",
    "        box_color = colors[label_idx % len(colors)]\n",
    "\n",
    "        draw.rectangle(box_coords, outline=box_color, width=2)\n",
    "        \n",
    "        if font:\n",
    "            # Get text size using textbbox for Pillow versions that support it\n",
    "            try:\n",
    "                text_bbox = draw.textbbox((xmin, ymin), label_text, font=font)\n",
    "                text_width = text_bbox[2] - text_bbox[0]\n",
    "                text_height = text_bbox[3] - text_bbox[1]\n",
    "            except AttributeError:\n",
    "                # Fallback for older Pillow versions\n",
    "                text_width, text_height = draw.textsize(label_text, font=font)\n",
    "            \n",
    "            # Position text above the box, or inside if it overflows\n",
    "            text_x = xmin\n",
    "            text_y = ymin - text_height - 2 # Position above the box\n",
    "            if text_y < 0: # If text goes off the top, place it inside\n",
    "                text_y = ymin + 2\n",
    "            \n",
    "            # Background for text for better readability\n",
    "            draw.rectangle([(text_x, text_y), (text_x + text_width, text_y + text_height)], fill=box_color)\n",
    "            draw.text((text_x, text_y), label_text, fill=\"black\", font=font)\n",
    "        else:\n",
    "            # Basic text drawing if font loading failed\n",
    "            draw.text((xmin + 2, ymin + 2), label_text, fill=box_color)\n",
    "            \n",
    "    return pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Inference and Display\n",
    "\n",
    "if model is not None: # Proceed only if model was loaded successfully\n",
    "    # Check if IMAGE_DIR exists, create if not, and provide instructions\n",
    "    if not os.path.exists(IMAGE_DIR):\n",
    "        print(f\"Test image directory '{IMAGE_DIR}' not found.\")\n",
    "        print(f\"Please create it in the project root (relative to this notebook: {os.path.abspath(IMAGE_DIR)}) and place test images there.\")\n",
    "        # As a fallback, let's try to create a dummy image if directory can be made\n",
    "        try:\n",
    "            os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "            dummy_img = Image.new('RGB', (600, 400), color = 'skyblue')\n",
    "            draw_dummy = ImageDraw.Draw(dummy_img)\n",
    "            try: font = ImageFont.load_default(); draw_dummy.text((50,180), \"Please replace with your test image!\", font=font, fill='black')\n",
    "            except: draw_dummy.text((50,180), \"Please replace with your test image!\", fill='black')\n",
    "            dummy_img_path = os.path.join(IMAGE_DIR, DEFAULT_TEST_IMAGE)\n",
    "            dummy_img.save(dummy_img_path)\n",
    "            print(f\"Created a dummy image at {dummy_img_path}. Please replace it with a real test image.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create dummy image directory/file: {e}\")\n",
    "            DEFAULT_TEST_IMAGE = None # Cannot proceed with image loading\n",
    "    \n",
    "    if DEFAULT_TEST_IMAGE:\n",
    "        test_image_path = os.path.join(IMAGE_DIR, DEFAULT_TEST_IMAGE)\n",
    "\n",
    "        if not os.path.exists(test_image_path):\n",
    "            print(f\"Test image '{DEFAULT_TEST_IMAGE}' not found in '{IMAGE_DIR}'.\")\n",
    "            print(\"Please place an image there or update DEFAULT_TEST_IMAGE in Cell 3.\")\n",
    "        else:\n",
    "            img_tensor, original_pil = prepare_image(test_image_path, IMAGE_SIZE, DEVICE)\n",
    "\n",
    "            if img_tensor is not None and original_pil is not None:\n",
    "                with torch.no_grad():\n",
    "                    # Model returns: cls_logits, bbox_pred_cxcywh, default_boxes_xyxy\n",
    "                    cls_logits, bbox_pred_cxcywh, _ = model(img_tensor)\n",
    "\n",
    "                # Process predictions for the single image (index 0 of batch)\n",
    "                pred_scores_softmax = torch.softmax(cls_logits[0], dim=-1) # (num_default_boxes, num_classes_loss)\n",
    "                pred_boxes_cxcywh = bbox_pred_cxcywh[0]                   # (num_default_boxes, 4)\n",
    "                \n",
    "                # Convert predicted boxes from [cx, cy, w, h] to [xmin, ymin, xmax, ymax] (still normalized)\n",
    "                pred_boxes_xyxy_norm = utils.box_cxcywh_to_xyxy(pred_boxes_cxcywh)\n",
    "\n",
    "                all_final_pred_boxes = []\n",
    "                all_final_pred_labels = []\n",
    "                all_final_pred_scores = []\n",
    "\n",
    "                # Iterate through foreground classes to apply NMS per class\n",
    "                for cls_idx in range(NUM_CLASSES_FG):\n",
    "                    class_scores = pred_scores_softmax[:, cls_idx + 1] # Scores for current fg class (skip background)\n",
    "                    \n",
    "                    # Filter by score threshold before NMS\n",
    "                    score_filter_mask = class_scores >= SCORE_THRESHOLD_DISPLAY \n",
    "                    if score_filter_mask.sum() == 0:\n",
    "                        continue\n",
    "\n",
    "                    current_class_scores = class_scores[score_filter_mask]\n",
    "                    current_class_boxes_xyxy = pred_boxes_xyxy_norm[score_filter_mask]\n",
    "                    \n",
    "                    # Apply Non-Maximum Suppression\n",
    "                    # NMS expects absolute coordinates if images vary greatly, but normalized is fine here as all inputs are resized.\n",
    "                    # However, utils.non_max_suppression might internally assume absolute if not careful.\n",
    "                    # For consistency with evaluate.py, let's assume NMS can handle normalized or that utils.non_max_suppression is robust.\n",
    "                    # If NMS needed absolute for some reason: current_class_boxes_abs = current_class_boxes_xyxy * IMAGE_SIZE\n",
    "                    keep_indices = utils.non_max_suppression(\n",
    "                        current_class_boxes_xyxy, # Normalized boxes\n",
    "                        current_class_scores,\n",
    "                        IOU_THRESHOLD_NMS\n",
    "                    )\n",
    "\n",
    "                    all_final_pred_boxes.append(current_class_boxes_xyxy[keep_indices])\n",
    "                    all_final_pred_labels.append(torch.full_like(current_class_scores[keep_indices], cls_idx, dtype=torch.long))\n",
    "                    all_final_pred_scores.append(current_class_scores[keep_indices])\n",
    "                \n",
    "                if len(all_final_pred_boxes) > 0:\n",
    "                    final_boxes = torch.cat(all_final_pred_boxes).cpu()    # Normalized xyxy\n",
    "                    final_labels = torch.cat(all_final_pred_labels).cpu()  # Foreground class indices (0 to N-1)\n",
    "                    final_scores = torch.cat(all_final_pred_scores).cpu()\n",
    "\n",
    "                    result_img_pil = draw_boxes_on_image(\n",
    "                        original_pil.copy(), \n",
    "                        final_boxes, \n",
    "                        final_labels, \n",
    "                        final_scores, \n",
    "                        PASCAL_VOC_CLASSES, # Pass the tuple of fg class names\n",
    "                        SCORE_THRESHOLD_DISPLAY\n",
    "                    )\n",
    "                    print(f\"Detected {final_boxes.shape[0]} objects above threshold.\")\n",
    "                else:\n",
    "                    result_img_pil = original_pil # No detections above threshold\n",
    "                    print(\"No objects detected above the threshold.\")\n",
    "\n",
    "                # Display using Matplotlib\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                plt.imshow(result_img_pil)\n",
    "                plt.title(f\"Detections on: {os.path.basename(test_image_path)}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "else:\n",
    "    print(\"Model not loaded. Cannot perform inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for Use\n",
    "\n",
    "1.  **Place Trained Checkpoint:** \n",
    "    *   Ensure your trained model checkpoint (e.g., `checkpoint_best.pth`) is located in the `object_detector/models_checkpoints/` directory (relative to the project root).\n",
    "    *   If your checkpoint file has a different name or path, update the `CHECKPOINT_PATH` variable in **Cell 3 (Configuration)**.\n",
    "\n",
    "2.  **Create Test Image Directory:**\n",
    "    *   Create a directory named `test_images` in the project root (e.g., `object_detector/test_images/`).\n",
    "    *   Place the images you want to test your model on into this `test_images/` directory.\n",
    "\n",
    "3.  **Set Test Image Name:**\n",
    "    *   In **Cell 3 (Configuration)**, modify the `DEFAULT_TEST_IMAGE` variable to the filename of the image you want to process (e.g., `\"my_test_image.jpg\"`). This image should be inside the `IMAGE_DIR` specified.\n",
    "\n",
    "4.  **Run All Cells:**\n",
    "    *   From the Jupyter Notebook menu, select \"Cell\" -> \"Run All\" or use the corresponding toolbar button.\n",
    "    *   The notebook will load the model, process the specified image, and display the image with detected bounding boxes.\n",
    "\n",
    "**Notes:**\n",
    "*   The `IMAGE_SIZE` in **Cell 3** should match the image size your model was trained with (default is 300x300).\n",
    "*   You can adjust `SCORE_THRESHOLD_DISPLAY` to control how sensitive the display of detections is. Lower values will show more (potentially less confident) detections.\n",
    "*   If the model or image files are not found, the notebook will print error messages. Please check the paths and filenames carefully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
